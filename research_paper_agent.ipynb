{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hongyoosung/Research_Paper_Writing_Agent/blob/main/research_paper_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-1"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Complete Research Paper Writing Agent using OpenAI API (gpt-4o-mini)\n",
        "\"\"\"\n",
        "\n",
        "# Cell 1: 필요한 라이브러리 설치 및 구글 드라이브 마운트\n",
        "!pip install -q openai chromadb arxiv requests torch sentence-transformers langdetect scikit-learn rouge\n",
        "!apt-get update -q\n",
        "!apt-get install -y -q texlive texlive-latex-extra texlive-fonts-recommended texlive-science texlive-publishers\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-2"
      },
      "outputs": [],
      "source": [
        "# Cell 2: 필요한 모듈 임포트\n",
        "import os\n",
        "import datetime\n",
        "import json\n",
        "import time\n",
        "import requests\n",
        "import re\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import arxiv\n",
        "import chromadb\n",
        "from google.colab import files\n",
        "from google.colab import userdata\n",
        "from langdetect import detect\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from openai import OpenAI\n",
        "from requests.adapters import HTTPAdapter\n",
        "from urllib3.util.retry import Retry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-13"
      },
      "outputs": [],
      "source": [
        "# Cell 3: 연구 주제 설정\n",
        "RESEARCH_TOPIC = \"minimizing prompt bloat in single-agent systems using Language Models with GOAP and decision trees\"\n",
        "KEYWORDS = \"prompt bloat prompt optimization language model single agent\"\n",
        "TITLE_PROMPT = f\"\"\"You are the most intelligent and innovative AI, capable of producing groundbreaking and feasible research. Generate a compelling and specific academic paper title for research on {RESEARCH_TOPIC}. The title should be concise (10-15 words), informative, and highlight efficiency improvements in agent performance. Provide only the title without any additional explanation. Ensure 'LLM' refers to 'Language Models'. Do not use Markdown formatting.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-14"
      },
      "outputs": [],
      "source": [
        "# Cell 4: 논문 길이 설정\n",
        "SECTION_LENGTHS = {\n",
        "    'abstract': 300,    # 약 250-400 단어\n",
        "    'introduction': 600, # 약 500-700 단어\n",
        "    'related_work': 700, # 약 600-800 단어\n",
        "    'methodology': 800,  # 약 700-900 단어\n",
        "    'experiments': 700,  # 약 600-850 단어\n",
        "    'conclusion': 400    # 약 300-400 단어\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-3"
      },
      "outputs": [],
      "source": [
        "# Cell 5: 작업 디렉토리 설정\n",
        "folder_name = datetime.datetime.now().strftime(\"research_paper_%Y%m%d_%H%M%S\")\n",
        "output_dir = f\"/content/drive/MyDrive/Research_Papers/{folder_name}\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "os.chdir(output_dir)\n",
        "print(f\"작업 디렉토리: {output_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-4"
      },
      "outputs": [],
      "source": [
        "# Cell 6: 로깅 유틸리티 설정\n",
        "class ResearchLogger:\n",
        "    def __init__(self, output_dir):\n",
        "        self.log_file = os.path.join(output_dir, 'research_log.txt')\n",
        "        self.start_time = time.time()\n",
        "        self.output_dir = output_dir\n",
        "\n",
        "    def log(self, message, level='INFO'):\n",
        "        current_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "        elapsed_time = time.time() - self.start_time\n",
        "        hours = int(elapsed_time // 3600)\n",
        "        minutes = int((elapsed_time % 3600) // 60)\n",
        "        seconds = int(elapsed_time % 60)\n",
        "\n",
        "        log_message = f\"[{current_time}] [{level}] [Elapsed: {hours:02d}:{minutes:02d}:{seconds:02d}] {message}\"\n",
        "\n",
        "        print(log_message)\n",
        "        with open(self.log_file, 'a', encoding='utf-8') as f:\n",
        "            f.write(log_message + '\\n')\n",
        "\n",
        "logger = ResearchLogger(output_dir)\n",
        "logger.log(f\"연구 논문 작성 에이전트 시작 - 작업 디렉토리: {output_dir}\", \"START\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-5"
      },
      "outputs": [],
      "source": [
        "# Cell 7: LaTeX PDF 생성 테스트\n",
        "logger.log(\"LaTeX PDF 생성 테스트 시작\")\n",
        "\n",
        "test_latex = r\"\"\"\n",
        "\\documentclass{article}\n",
        "\\usepackage[utf8]{inputenc}\n",
        "\\begin{document}\n",
        "\\title{LaTeX Test Document}\n",
        "\\author{Test Author}\n",
        "\\date{\\today}\n",
        "\\maketitle\n",
        "This is a test document to verify LaTeX installation.\n",
        "\\section{Test Section}\n",
        "Testing LaTeX compilation with UTF-8 encoding.\n",
        "\\end{document}\n",
        "\"\"\"\n",
        "\n",
        "test_tex_path = os.path.join(output_dir, 'test.tex')\n",
        "test_pdf_path = os.path.join(output_dir, 'test.pdf')\n",
        "\n",
        "with open(test_tex_path, 'w', encoding='utf-8') as f:\n",
        "    f.write(test_latex)\n",
        "\n",
        "result = os.system(f'cd {output_dir} && pdflatex -interaction=nonstopmode test.tex > test_compile.log 2>&1')\n",
        "\n",
        "if os.path.exists(test_pdf_path):\n",
        "    logger.log(\"LaTeX 테스트 성공: PDF 생성 확인\")\n",
        "else:\n",
        "    logger.log(\"LaTeX 테스트 실패: PDF 생성 불가\", \"ERROR\")\n",
        "    with open(os.path.join(output_dir, 'test_compile.log'), 'r') as f:\n",
        "        logger.log(f\"컴파일 로그:\\n{f.read()}\", \"ERROR\")\n",
        "    raise Exception(\"LaTeX setup failed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-6"
      },
      "outputs": [],
      "source": [
        "# Cell 8: OpenAI API 클라이언트 설정\n",
        "logger.log(\"OpenAI API 클라이언트 초기화 시작\")\n",
        "try:\n",
        "    api_key = userdata.get('OPENAI')\n",
        "    if not api_key:\n",
        "        raise ValueError(\"OPENAI 비밀키가 설정되지 않았습니다.\")\n",
        "    client = OpenAI(api_key=api_key)\n",
        "    logger.log(\"OpenAI API 클라이언트 초기화 완료\")\n",
        "except Exception as e:\n",
        "    logger.log(f\"OpenAI API 초기화 실패: {str(e)}\", \"ERROR\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-7"
      },
      "outputs": [],
      "source": [
        "# Cell 9: Chroma DB를 위한 임베딩 모델 설정\n",
        "logger.log(\"임베딩 모델 로딩 시작\")\n",
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "logger.log(\"임베딩 모델 로딩 완료\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-8"
      },
      "outputs": [],
      "source": [
        "# Cell 10: Chroma DB 초기화\n",
        "logger.log(\"Chroma DB 초기화 시작\")\n",
        "chroma_client = chromadb.Client()\n",
        "\n",
        "try:\n",
        "    collection = chroma_client.create_collection(\n",
        "        name=\"research_papers\",\n",
        "        get_or_create=True\n",
        "    )\n",
        "    logger.log(\"Chroma DB 초기화 완료\")\n",
        "except Exception as e:\n",
        "    logger.log(f\"Chroma DB 초기화 실패: {str(e)}\", \"ERROR\")\n",
        "    try:\n",
        "        chroma_client.delete_collection(\"research_papers\")\n",
        "        logger.log(\"기존 research_papers 컬렉션 삭제\")\n",
        "        collection = chroma_client.create_collection(\"research_papers\")\n",
        "        logger.log(\"새 research_papers 컬렉션 생성 완료\")\n",
        "    except Exception as e2:\n",
        "        logger.log(f\"컬렉션 재생성 실패: {str(e2)}\", \"ERROR\")\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-9"
      },
      "outputs": [],
      "source": [
        "# Cell 11: 텍스트 생성 함수 - OpenAI API (gpt-4o-mini) 사용\n",
        "def generate_text(prompt, max_length=800, temperature=0.7, max_attempts=3):\n",
        "    best_text = \"\"\n",
        "    best_score = -1\n",
        "    model = \"gpt-4o-mini\"\n",
        "\n",
        "    for attempt in range(max_attempts):\n",
        "        try:\n",
        "            messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "            response = client.chat.completions.create(\n",
        "                model=model,\n",
        "                messages=messages,\n",
        "                max_tokens=max_length,\n",
        "                temperature=temperature + (attempt * 0.1),\n",
        "                top_p=0.9\n",
        "            )\n",
        "\n",
        "            generated_text = response.choices[0].message.content.strip()\n",
        "\n",
        "            # 프롬프트 관련 텍스트 제거 (인용 패턴은 유지)\n",
        "            prompt_patterns = [\n",
        "                r\"Write a.*?\\n\",\n",
        "                r\"Include:.*?\\n\",\n",
        "                r\"1\\..*?\\n\",\n",
        "                r\"Ensure '.*?\\n\",\n",
        "                r\"Do not use Markdown.*?\\n\",\n",
        "                r\"You are the most.*?\\n\"\n",
        "            ]\n",
        "            for pattern in prompt_patterns:\n",
        "                try:\n",
        "                    generated_text = re.sub(pattern, \"\", generated_text, flags=re.DOTALL)\n",
        "                except Exception as e:\n",
        "                    logger.log(f\"프롬프트 제거 오류: {str(e)}\", \"WARNING\")\n",
        "                    continue\n",
        "\n",
        "            logger.log(f\"생성된 텍스트 시작 (시도 {attempt+1}): {generated_text[:100]}...\")\n",
        "\n",
        "            word_count = len(generated_text.split())\n",
        "            score = word_count / max_length if word_count > 50 else 0\n",
        "\n",
        "            logger.log(f\"시도 {attempt+1}/{max_attempts}: {word_count} words, 점수: {score:.2f}\")\n",
        "\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_text = generated_text\n",
        "\n",
        "            if best_score > 0.9:\n",
        "                break\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.log(f\"텍스트 생성 오류 (시도 {attempt+1}): {str(e)}\", \"WARNING\")\n",
        "            time.sleep(2)\n",
        "            continue\n",
        "\n",
        "    if best_text:\n",
        "        logger.log(f\"최종 텍스트 선택: {len(best_text.split())} words, 점수: {best_score:.2f}\")\n",
        "        return best_text\n",
        "    else:\n",
        "        logger.log(\"텍스트 생성 실패: 모든 시도에서 유효한 결과 없음\", \"ERROR\")\n",
        "        return \"Error generating text\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-10"
      },
      "outputs": [],
      "source": [
        "# Cell 12: ArXiv에서 논문 수집 함수\n",
        "def fetch_papers(keywords, num_papers=10):\n",
        "    logger.log(f\"ArXiv에서 논문 검색 시작: {keywords}\")\n",
        "\n",
        "    session = requests.Session()\n",
        "    retries = Retry(total=3, backoff_factor=1, status_forcelist=[429, 500, 502, 503, 504])\n",
        "    session.mount('http://', HTTPAdapter(max_retries=retries))\n",
        "    session.mount('https://', HTTPAdapter(max_retries=retries))\n",
        "\n",
        "    client = arxiv.Client()\n",
        "    search = arxiv.Search(\n",
        "        query=keywords + \" AND (language model OR prompt optimization OR prompt compression)\",\n",
        "        max_results=num_papers * 2,\n",
        "        sort_by=arxiv.SortCriterion.Relevance\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        papers = list(client.results(search))\n",
        "        logger.log(f\"원본 논문 수: {len(papers)}\")\n",
        "\n",
        "        filtered_papers = [p for p in papers if any(term in p.summary.lower() for term in [\"language model\", \"prompt\", \"agent\"])]\n",
        "        logger.log(f\"필터링 후 논문 수: {len(filtered_papers)}\")\n",
        "\n",
        "        bibtex_entries = []\n",
        "        seen_titles = set()\n",
        "\n",
        "        for i, paper in enumerate(filtered_papers[:num_papers]):\n",
        "            try:\n",
        "                if paper.title in seen_titles:\n",
        "                    continue\n",
        "                seen_titles.add(paper.title)\n",
        "                arxiv_id = paper.entry_id.split('/')[-1]\n",
        "\n",
        "                # Create a backup bibtex entry\n",
        "                backup_bibtex = f\"\"\"@article{{paper{i},\n",
        "  author = {{{', '.join([author.name for author in paper.authors])}}},\n",
        "  title = {{{paper.title}}},\n",
        "  journal = {{arXiv preprint arXiv:{arxiv_id}}},\n",
        "  year = {{{paper.published.year}}},\n",
        "  url = {{{paper.entry_id}}},\n",
        "}}\"\"\"\n",
        "\n",
        "                bibtex_url = f\"http://arxiv.org/bibtex/{arxiv_id}\"\n",
        "                response = session.get(bibtex_url, timeout=10)\n",
        "                if response.status_code == 200:\n",
        "                    bibtex_entry = response.text.strip()\n",
        "                    bibtex_entry = re.sub(r'@article{[^,]+,', f'@article{{paper{i},', bibtex_entry)\n",
        "                    if not bibtex_entry.strip().endswith(\"}\"):\n",
        "                        bibtex_entry = bibtex_entry.strip() + \"\\n}\"\n",
        "                    bibtex_entries.append(bibtex_entry)\n",
        "                    logger.log(f\"논문 {i+1} BibTeX 수집 완료: {paper.title[:50]}...\")\n",
        "                else:\n",
        "                    logger.log(f\"논문 {i+1} BibTeT 요청 실패: 상태 코드 {response.status_code}. 백업 항목 사용\", \"WARNING\")\n",
        "                    bibtex_entries.append(backup_bibtex)\n",
        "            except Exception as e:\n",
        "                logger.log(f\"논문 {i+1} BibTeX 수집 실패: {str(e)}. 백업 항목 사용\", \"WARNING\")\n",
        "                try:\n",
        "                    bibtex_entries.append(backup_bibtex)\n",
        "                except Exception as e2:\n",
        "                    logger.log(f\"백업 BibTeX 생성 실패: {str(e2)}\", \"ERROR\")\n",
        "\n",
        "        logger.log(f\"수집된 논문: {len(filtered_papers)}개, 고유 BibTeX 항목: {len(bibtex_entries)}개\")\n",
        "        return filtered_papers[:num_papers], bibtex_entries\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.log(f\"ArXiv 검색 실패: {str(e)}\", \"ERROR\")\n",
        "        return [], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-11"
      },
      "outputs": [],
      "source": [
        "# Cell 13: RAG 쿼리 함수\n",
        "def rag_query(query, n_results=3):\n",
        "    query_vector = embedder.encode(query).tolist()\n",
        "    results = collection.query(\n",
        "        query_embeddings=[query_vector],\n",
        "        n_results=n_results\n",
        "    )\n",
        "    return results['documents'][0] if results['documents'] else [], results['metadatas'][0] if results['metadatas'] else []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-12"
      },
      "outputs": [],
      "source": [
        "# Cell 14: 품질 평가 함수\n",
        "def calculate_quality_score(section_text, section_type):\n",
        "    scores = {}\n",
        "    word_count = len(section_text.split())\n",
        "    expected_lengths = {\n",
        "        'abstract': 150,\n",
        "        'introduction': 300,\n",
        "        'related_work': 400,\n",
        "        'methodology': 500,\n",
        "        'experiments': 400,\n",
        "        'conclusion': 200\n",
        "    }\n",
        "    expected = expected_lengths.get(section_type, 300)\n",
        "    length_score = min(word_count / expected, 1.5) * 0.9 if word_count > 50 else 0.5\n",
        "    scores['length'] = length_score\n",
        "\n",
        "    llm_mentions = section_text.lower().count(\"language model\") + section_text.lower().count(\"prompt bloat\")\n",
        "    llm_score = min(llm_mentions / 3, 1.0)\n",
        "    scores['llm_relevance'] = llm_score\n",
        "\n",
        "    if section_type == 'related_work':\n",
        "        citation_pattern = r'\\[paper\\d+\\]'\n",
        "        citations = re.findall(citation_pattern, section_text)\n",
        "        citation_score = min(len(citations) / 3, 1.0)\n",
        "        scores['citations'] = citation_score\n",
        "    else:\n",
        "        scores['citations'] = 1.0\n",
        "\n",
        "    sentences = [s for s in section_text.split('.') if s.strip()]\n",
        "    if sentences:\n",
        "        avg_sentence_length = word_count / len(sentences)\n",
        "        readability_score = 1.0 if 10 <= avg_sentence_length <= 25 else 0.7\n",
        "        scores['readability'] = readability_score\n",
        "\n",
        "    total_score = sum(scores.values()) / len(scores)\n",
        "    return total_score, scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-15"
      },
      "outputs": [],
      "source": [
        "# Cell 15: 논문 제목 생성\n",
        "logger.log(\"논문 제목 생성 시작\")\n",
        "paper_title = generate_text(TITLE_PROMPT, max_length=100, temperature=0.8)\n",
        "if not paper_title or \"Error\" in paper_title:\n",
        "    paper_title = \"Optimizing Prompt Efficiency in Single-Agent LLMs with GOAP and Decision Trees\"\n",
        "\n",
        "logger.log(f\"생성된 논문 제목: {paper_title}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-16"
      },
      "outputs": [],
      "source": [
        "# Cell 16: 논문 수집 및 Chroma DB에 저장\n",
        "papers, bibtex_entries = fetch_papers(KEYWORDS, num_papers=10)\n",
        "\n",
        "for i, paper in enumerate(papers):\n",
        "    try:\n",
        "        summary = paper.summary[:3000]\n",
        "        vector = embedder.encode(summary).tolist()\n",
        "        collection.add(\n",
        "            documents=[summary],\n",
        "            metadatas=[{\n",
        "                \"title\": paper.title,\n",
        "                \"authors\": \", \".join([author.name for author in paper.authors]),\n",
        "                \"year\": str(paper.published.year),\n",
        "                \"bibtex_key\": f\"paper{i}\"\n",
        "            }],\n",
        "            ids=[str(paper.entry_id)],\n",
        "            embeddings=[vector]\n",
        "        )\n",
        "        logger.log(f\"논문 {i+1} 저장 완료\")\n",
        "    except Exception as e:\n",
        "        logger.log(f\"논문 {i+1} 처리 실패: {str(e)}\", \"WARNING\")\n",
        "\n",
        "bib_path = os.path.join(output_dir, 'references.bib')\n",
        "with open(bib_path, 'w', encoding='utf-8') as f:\n",
        "    f.write('\\n\\n'.join(bibtex_entries))\n",
        "logger.log(f\"References.bib 저장 완료: {bib_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-17"
      },
      "outputs": [],
      "source": [
        "# Cell 17: 섹션별 논문 생성\n",
        "sections = {}\n",
        "\n",
        "def generate_section(prompt, section_name, max_length, temperature=0.7, min_score=0.8):\n",
        "    attempt = 0\n",
        "    max_attempts = 3\n",
        "    best_text = \"\"\n",
        "    best_score = -1\n",
        "\n",
        "    prompt = f\"\"\"You are the most intelligent and innovative AI, capable of producing groundbreaking and feasible research. {prompt}\n",
        "\n",
        "IMPORTANT CITATION INSTRUCTIONS:\n",
        "1. Do not use Markdown formatting (e.g., **bold**, # Heading, - List).\n",
        "2. Write in plain text suitable for LaTeX.\n",
        "3. For citations, use the exact format [paper0], [paper1], etc. to match BibTeX keys in references.bib.\n",
        "4. Include multiple citations throughout the text where relevant to ensure proper reference generation.\"\"\"\n",
        "\n",
        "    while attempt < max_attempts:\n",
        "        text = generate_text(prompt, max_length=max_length, temperature=temperature)\n",
        "        if \"Error\" not in text:\n",
        "            citation_count = len(re.findall(r'\\[paper\\d+\\]', text))\n",
        "            if citation_count == 0 and section_name in [\"related_work\", \"introduction\"]:\n",
        "                logger.log(f\"{section_name}에 인용이 없음. 인용 추가 시도\", \"WARNING\")\n",
        "                text = add_random_citations(text, section_name)\n",
        "\n",
        "            score, details = calculate_quality_score(text, section_name)\n",
        "            logger.log(f\"{section_name} 생성 시도 {attempt+1}: 점수 {score:.2f}, 세부사항: {details}\")\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_text = text\n",
        "            if score >= min_score:\n",
        "                break\n",
        "        attempt += 1\n",
        "\n",
        "    if best_score < min_score:\n",
        "        logger.log(f\"{section_name} 최종 점수 {best_score:.2f}가 최소 기준 {min_score} 미달\", \"WARNING\")\n",
        "\n",
        "    return best_text\n",
        "\n",
        "def add_random_citations(text, section_name):\n",
        "    sentences = text.split('. ')\n",
        "    citation_pattern = r'\\[paper\\d+\\]'\n",
        "    has_citations = bool(re.search(citation_pattern, text))\n",
        "\n",
        "    if not has_citations:\n",
        "        num_to_cite = max(1, len(sentences) // 5)\n",
        "        indices = np.random.choice(range(len(sentences)), num_to_cite, replace=False)\n",
        "\n",
        "        for i in indices:\n",
        "            if i < len(sentences):\n",
        "                paper_num = np.random.randint(0, 9)\n",
        "                sentences[i] = sentences[i] + f\" [paper{paper_num}]\"\n",
        "\n",
        "        updated_text = '. '.join(sentences)\n",
        "        logger.log(f\"{section_name}에 {num_to_cite}개의 인용 자동 추가됨\", \"INFO\")\n",
        "        return updated_text\n",
        "\n",
        "    return text\n",
        "\n",
        "# Abstract 생성\n",
        "logger.log(\"Abstract 섹션 생성 시작\")\n",
        "abstract_prompt = f\"\"\"Write a comprehensive abstract (250-400 words) for an academic paper titled '{paper_title}'.\n",
        "The abstract should include:\n",
        "1. Background: Challenges of {RESEARCH_TOPIC.split(' in ')[0]} in {RESEARCH_TOPIC.split(' in ')[1].split(' using ')[0]}, such as increased latency and resource consumption.\n",
        "2. Approach: A novel method using {RESEARCH_TOPIC.split(' using ')[1].split(' and ')[0]} to design the overall prompt structure, with sub-goals mapped to prompt sections, and {RESEARCH_TOPIC.split(' and ')[1]} to evaluate and select optimal prompt configurations.\n",
        "3. Method: How {RESEARCH_TOPIC.split(' using ')[1].split(' and ')[0]} structures prompts and {RESEARCH_TOPIC.split(' and ')[1]} optimize clarity, conciseness, and LLM response accuracy.\n",
        "4. Results: Key findings showing reduced prompt size, lower inference time, and improved task performance.\n",
        "5. Significance: Implications for scalable and efficient {RESEARCH_TOPIC.split(' in ')[1].split(' using ')[0]}.\n",
        "\n",
        "Write in academic style, be specific, and use precise technical language. Ensure 'LLM' refers to 'Language Models' consistently. Cite relevant works as [paper0], [paper1], etc., ensuring citations match BibTeX keys in references.bib.\"\"\"\n",
        "\n",
        "abstract_text = generate_section(abstract_prompt, \"abstract\", max_length=SECTION_LENGTHS['abstract'], min_score=0.8)\n",
        "sections['abstract'] = abstract_text\n",
        "logger.log(f\"Abstract 생성 완료: {len(abstract_text.split())} words\")\n",
        "\n",
        "# Introduction 생성\n",
        "logger.log(\"Introduction 섹션 생성 시작\")\n",
        "intro_prompt = f\"\"\"Write an introduction (500-700 words) for the paper '{paper_title}'. Include:\n",
        "1. Opening: Current state of {RESEARCH_TOPIC.split(' in ')[1].split(' using ')[0]} and the challenge of {RESEARCH_TOPIC.split(' in ')[0]} with Language Models (LLMs).\n",
        "2. Problem statement: How {RESEARCH_TOPIC.split(' in ')[0]} increases computational overhead and degrades performance.\n",
        "3. Motivation: Importance of {RESEARCH_TOPIC.split(' in ')[0]} for efficient LLM-based agents.\n",
        "4. Research questions: How {RESEARCH_TOPIC.split(' using ')[1].split(' and ')[0]} and {RESEARCH_TOPIC.split(' and ')[1]} can reduce {RESEARCH_TOPIC.split(' in ')[0]} by structuring prompts and optimizing configurations.\n",
        "5. Contributions: A novel approach combining {RESEARCH_TOPIC.split(' using ')[1].split(' and ')[0]} for goal-oriented prompt design and {RESEARCH_TOPIC.split(' and ')[1]} for configuration optimization.\n",
        "6. Paper structure: Brief outline of remaining sections.\n",
        "\n",
        "Use formal academic language, ensure 'LLM' refers to 'Language Models', and cite relevant work as [paper0], [paper1], etc., matching BibTeX keys in references.bib.\"\"\"\n",
        "\n",
        "intro_text = generate_section(intro_prompt, \"introduction\", max_length=SECTION_LENGTHS['introduction'], min_score=0.8)\n",
        "sections['introduction'] = intro_text\n",
        "logger.log(f\"Introduction 생성 완료: {len(intro_text.split())} words\")\n",
        "\n",
        "# Related Work 생성\n",
        "logger.log(\"Related Work 섹션 생성 시작\")\n",
        "related_docs, related_metas = rag_query(f\"{RESEARCH_TOPIC.split(' in ')[0]} {RESEARCH_TOPIC.split(' in ')[1].split(' using ')[0]} language models\")\n",
        "related_context = \"\\n\".join([f\"{meta['title']} ({meta['bibtex_key']}): {doc[:200]}\" for doc, meta in zip(related_docs, related_metas)]) if related_docs else \"No related papers found. Discuss general trends.\"\n",
        "\n",
        "related_work_prompt = f\"\"\"Write a related work section (600-800 words) for '{paper_title}'.\n",
        "Based on these research summaries:\n",
        "{related_context}\n",
        "\n",
        "Structure the section with:\n",
        "1. {RESEARCH_TOPIC.split(' in ')[1].split(' using ')[0].capitalize()}: Evolution and challenges with Language Models (LLMs).\n",
        "2. {RESEARCH_TOPIC.split(' in ')[0].capitalize()}: Existing approaches to manage prompt complexity and their limitations.\n",
        "3. Optimization Techniques: Use of planning or decision-making methods (e.g., {RESEARCH_TOPIC.split(' using ')[1].split(' and ')[0]}, {RESEARCH_TOPIC.split(' and ')[1]}) in LLM prompt optimization.\n",
        "4. Gap Analysis: What's missing in current research on {RESEARCH_TOPIC.split(' in ')[0]} minimization, particularly in integrating structured planning and decision-making.\n",
        "\n",
        "Include citations as [paper0], [paper1], etc., matching BibTeX keys in references.bib for each summary provided. If no summaries, cite hypothetical [paper0], [paper1] for general trends. Use formal academic language and ensure 'LLM' refers to 'Language Models'.\"\"\"\n",
        "\n",
        "related_work_text = generate_section(related_work_prompt, \"related_work\", max_length=SECTION_LENGTHS['related_work'], min_score=0.8)\n",
        "sections['related_work'] = related_work_text\n",
        "logger.log(f\"Related Work 생성 완료: {len(related_work_text.split())} words\")\n",
        "\n",
        "# Methodology 생성\n",
        "logger.log(\"Methodology 섹션 생성 시작\")\n",
        "methodology_prompt = f\"\"\"Write a detailed methodology section (700-900 words) for '{paper_title}'. Include:\n",
        "\n",
        "1. System Architecture:\n",
        "   - {RESEARCH_TOPIC.split(' in ')[1].split(' using ')[0].capitalize()} framework design with Language Models (LLMs)\n",
        "   - Prompt management pipeline using {RESEARCH_TOPIC.split(' using ')[1].split(' and ')[0]}\n",
        "\n",
        "2. {RESEARCH_TOPIC.split(' in ')[0].capitalize()} Minimization Techniques:\n",
        "   - {RESEARCH_TOPIC.split(' using ')[1].split(' and ')[0]} for designing goal-oriented prompt structures, mapping sub-goals to prompt sections (e.g., task instructions, context, output format)\n",
        "   - {RESEARCH_TOPIC.split(' and ')[1].capitalize()} for evaluating prompt section configurations (e.g., specificity level, role detail, output format options) based on clarity, conciseness, and LLM response accuracy\n",
        "   - Iterative optimization process to refine the overall prompt structure\n",
        "\n",
        "3. Implementation Details:\n",
        "   - Technical specifications for LLM integration\n",
        "   - Evaluation criteria for {RESEARCH_TOPIC.split(' and ')[1]} (e.g., prompt size, response accuracy, inference time)\n",
        "   - Pseudocode for {RESEARCH_TOPIC.split(' using ')[1].split(' and ')[0]}-based prompt structuring and {RESEARCH_TOPIC.split(' and ')[1]} evaluation\n",
        "\n",
        "Use technical language, ensure 'LLM' refers to 'Language Models', include pseudocode, and cite relevant work as [paper0], [paper1], etc., matching BibTeX keys in references.bib.\"\"\"\n",
        "\n",
        "methodology_text = generate_section(methodology_prompt, \"methodology\", max_length=SECTION_LENGTHS['methodology'], min_score=0.8)\n",
        "sections['methodology'] = methodology_text\n",
        "logger.log(f\"Methodology 생성 완료: {len(methodology_text.split())} words\")\n",
        "\n",
        "# Experiments 생성\n",
        "logger.log(\"Experiments 섹션 생성 시작\")\n",
        "experiments_prompt = f\"\"\"Write an experiments section (600-850 words) for '{paper_title}'. Include:\n",
        "\n",
        "1. Experimental Setup:\n",
        "   - Hardware/software specs for Language Models (LLMs)\n",
        "   - Datasets and simulation environments for {RESEARCH_TOPIC.split(' in ')[1].split(' using ')[0]} tasks\n",
        "   - Baseline systems for comparison (e.g., unoptimized LLM prompts)\n",
        "\n",
        "2. Evaluation Metrics:\n",
        "   - Prompt size (e.g., token count)\n",
        "   - Inference time and resource usage\n",
        "   - Task performance (e.g., accuracy, completion rate)\n",
        "\n",
        "3. Results:\n",
        "   - Performance comparisons with baselines\n",
        "   - Effectiveness of {RESEARCH_TOPIC.split(' using ')[1].split(' and ')[0]}-based prompt structuring and {RESEARCH_TOPIC.split(' and ')[1]}-based configuration optimization\n",
        "   - Impact on {RESEARCH_TOPIC.split(' in ')[0]} reduction\n",
        "\n",
        "4. Discussion:\n",
        "   - Result interpretation\n",
        "   - Trade-offs and limitations of the {RESEARCH_TOPIC.split(' using ')[1].split(' and ')[0]} and {RESEARCH_TOPIC.split(' and ')[1]} approach\n",
        "   - Insights for future LLM optimizations\n",
        "\n",
        "Include specific numbers/tables, ensure 'LLM' refers to 'Language Models', and cite relevant work as [paper0], [paper1], etc., matching BibTeX keys in references.bib.\"\"\"\n",
        "\n",
        "experiments_text = generate_section(experiments_prompt, \"experiments\", max_length=SECTION_LENGTHS['experiments'], min_score=0.8)\n",
        "sections['experiments'] = experiments_text\n",
        "logger.log(f\"Experiments 생성 완료: {len(experiments_text.split())} words\")\n",
        "\n",
        "# Conclusion 생성\n",
        "logger.log(\"Conclusion 섹션 생성 시작\")\n",
        "conclusion_prompt = f\"\"\"Write a conclusion (300-400 words) for '{paper_title}'. Include:\n",
        "1. Summary: Key findings on {RESEARCH_TOPIC} using Language Models (LLMs) with {RESEARCH_TOPIC.split(' using ')[1].split(' and ')[0]} and {RESEARCH_TOPIC.split(' and ')[1]}.\n",
        "2. Implications: Advances in efficient {RESEARCH_TOPIC.split(' in ')[1].split(' using ')[0]}.\n",
        "3. Limitations: Current constraints of LLMs and the proposed {RESEARCH_TOPIC.split(' using ')[1].split(' and ')[0]} and {RESEARCH_TOPIC.split(' and ')[1]} methods.\n",
        "4. Future Work: Directions for further reducing {RESEARCH_TOPIC.split(' in ')[0]} and enhancing LLM scalability.\n",
        "5. Final Thoughts: Broader impact on AI research.\n",
        "\n",
        "Be concise, ensure 'LLM' refers to 'Language Models', cite relevant work as [paper0], [paper1], etc., matching BibTeX keys in references.bib, and avoid new information.\"\"\"\n",
        "\n",
        "conclusion_text = generate_section(conclusion_prompt, \"conclusion\", max_length=SECTION_LENGTHS['conclusion'], min_score=0.8)\n",
        "sections['conclusion'] = conclusion_text\n",
        "logger.log(f\"Conclusion 생성 완료: {len(conclusion_text.split())} words\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-18"
      },
      "outputs": [],
      "source": [
        "# Cell 18: 마크다운 변환 및 LaTeX 생성 함수\n",
        "def markdown_to_latex(text):\n",
        "    if not text:\n",
        "        return text\n",
        "\n",
        "    logger.log(f\"markdown_to_latex 입력: {text[:100]}...\")\n",
        "\n",
        "    try:\n",
        "        text = re.sub(r'^# (.*?)$', r'\\section{\\1}', text, flags=re.MULTILINE)\n",
        "        text = re.sub(r'^## (.*?)$', r'\\subsection{\\1}', text, flags=re.MULTILINE)\n",
        "        text = re.sub(r'^### (.*?)$', r'\\subsubsection{\\1}', text, flags=re.MULTILINE)\n",
        "        text = re.sub(r'\\*\\*(.*?)\\*\\*', r'\\textbf{\\1}', text)\n",
        "        text = re.sub(r'__(.*?)__', r'\\textbf{\\1}', text)\n",
        "        text = re.sub(r'\\*(.*?)\\*', r'\\textit{\\1}', text)\n",
        "        text = re.sub(r'_(.*?)_', r'\\textit{\\1}', text)\n",
        "        text = re.sub(r'```(.*?)```', r'\\begin{verbatim}\\1\\end{verbatim}', text, flags=re.DOTALL)\n",
        "        text = re.sub(r'`(.*?)`', r'\\texttt{\\1}', text)\n",
        "        text = re.sub(r'\\[(.*?)\\]\\((.*?)\\)', r'\\1', text)\n",
        "        text = re.sub(r'\\[paper(\\d+)\\]', r'\\\\cite{paper\\1}', text)\n",
        "    except Exception as e:\n",
        "        logger.log(f\"마크다운 변환 오류: {str(e)}\", \"WARNING\")\n",
        "\n",
        "    lines = text.split('\\n')\n",
        "    result = []\n",
        "    in_list = False\n",
        "    list_items = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip().startswith('- '):\n",
        "            if not in_list:\n",
        "                in_list = True\n",
        "                list_items = []\n",
        "            list_items.append(r'\\item ' + line[2:].strip())\n",
        "        else:\n",
        "            if in_list:\n",
        "                if list_items:\n",
        "                    result.append(r'\\begin{itemize}')\n",
        "                    result.extend(list_items)\n",
        "                    result.append(r'\\end{itemize}')\n",
        "                in_list = False\n",
        "            result.append(line)\n",
        "\n",
        "    if in_list and list_items:\n",
        "        result.append(r'\\begin{itemize}')\n",
        "        result.extend(list_items)\n",
        "        result.append(r'\\end{itemize}')\n",
        "\n",
        "    text = '\\n'.join(result)\n",
        "\n",
        "    logger.log(f\"markdown_to_latex 출력: {text[:100]}...\")\n",
        "    return text\n",
        "\n",
        "def escape_latex(text):\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    replacements = {\n",
        "        '\\\\': r'\\textbackslash{}',\n",
        "        '&': r'\\&',\n",
        "        '%': r'\\%',\n",
        "        '$': r'\\$',\n",
        "        '#': r'\\#',\n",
        "        '_': r'\\_',\n",
        "        '{': r'\\{',\n",
        "        '}': r'\\}',\n",
        "        '~': r'\\textasciitilde{}',\n",
        "        '^': r'\\textasciicircum{}'\n",
        "    }\n",
        "    text = text.replace('\\\\', r'\\textbackslash{}')\n",
        "    for char, replacement in replacements.items():\n",
        "        if char != '\\\\':\n",
        "            text = text.replace(char, replacement)\n",
        "    return text\n",
        "\n",
        "def generate_latex_and_save_pdf(sections_dict, title, filename_suffix=\"\"):\n",
        "    escaped_title = escape_latex(title)\n",
        "    escaped_sections = {}\n",
        "\n",
        "    for key, value in sections_dict.items():\n",
        "        try:\n",
        "            escaped_sections[key] = escape_latex(markdown_to_latex(value))\n",
        "        except Exception as e:\n",
        "            logger.log(f\"섹션 {key} LaTeX 변환 실패: {str(e)}\", \"ERROR\")\n",
        "            escaped_sections[key] = value\n",
        "\n",
        "    latex_code = rf\"\"\"\n",
        "\\documentclass[conference]{{IEEEtran}}\n",
        "\\usepackage[utf8]{{inputenc}}\n",
        "\\usepackage{{amsmath,amsfonts,amssymb}}\n",
        "\\usepackage{{graphicx}}\n",
        "\\usepackage{{cite}}\n",
        "\\usepackage{{url}}\n",
        "\\usepackage{{booktabs}}\n",
        "\\usepackage{{listings}}\n",
        "\\usepackage{{hyperref}}\n",
        "\\usepackage{{xcolor}}\n",
        "\n",
        "\\begin{{document}}\n",
        "\n",
        "\\title{{{escaped_title}}}\n",
        "\n",
        "\\author{{\n",
        "\\IEEEauthorblockN{{Research Agent}}\n",
        "\\IEEEauthorblockA{{Automated Research System\\\\\n",
        "YoosungHong\\\\\n",
        "Email: research@agent.ai}}\n",
        "}}\n",
        "\n",
        "\\maketitle\n",
        "\n",
        "\\begin{{abstract}}\n",
        "{escaped_sections.get('abstract', 'Abstract content not available.')}\n",
        "\\end{{abstract}}\n",
        "\n",
        "\\begin{{IEEEkeywords}}\n",
        "Prompt Bloat, Single-Agent Systems, Language Models, Efficiency\n",
        "\\end{{IEEEkeywords}}\n",
        "\n",
        "\\section{{Introduction}}\n",
        "{escaped_sections.get('introduction', 'Introduction content not available.')}\n",
        "\n",
        "\\section{{Related Work}}\n",
        "{escaped_sections.get('related_work', 'Related work content not available.')}\n",
        "\n",
        "\\section{{Methodology}}\n",
        "{escaped_sections.get('methodology', 'Methodology content not available.')}\n",
        "\n",
        "\\section{{Experiments}}\n",
        "{escaped_sections.get('experiments', 'Experiments content not available.')}\n",
        "\n",
        "\\section{{Conclusion}}\n",
        "{escaped_sections.get('conclusion', 'Conclusion content not available.')}\n",
        "\n",
        "\\bibliographystyle{{IEEEtran}}\n",
        "\\bibliography{{references}}\n",
        "\n",
        "\\end{{document}}\n",
        "\"\"\"\n",
        "\n",
        "    tex_filename = f'paper{filename_suffix}.tex'\n",
        "    pdf_filename = f'paper{filename_suffix}.pdf'\n",
        "    tex_path = os.path.join(output_dir, tex_filename)\n",
        "    pdf_path = os.path.join(output_dir, pdf_filename)\n",
        "\n",
        "    with open(tex_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(latex_code)\n",
        "\n",
        "    logger.log(f\"LaTeX 파일 저장: {tex_path}\")\n",
        "\n",
        "    bib_path = os.path.join(output_dir, 'references.bib')\n",
        "    if os.path.exists(bib_path):\n",
        "        with open(bib_path, 'r', encoding='utf-8') as f:\n",
        "            bib_content = f.read()\n",
        "            logger.log(f\"References.bib 파일 존재 (크기: {len(bib_content)} bytes)\")\n",
        "            logger.log(f\"BibTeX 내용 샘플: {bib_content[:200]}...\")\n",
        "    else:\n",
        "        logger.log(\"References.bib 파일이 존재하지 않음!\", \"ERROR\")\n",
        "\n",
        "    compile_steps = [\n",
        "        f'cd {output_dir} && pdflatex -interaction=nonstopmode {tex_filename}',\n",
        "        f'cd {output_dir} && bibtex paper{filename_suffix}',\n",
        "        f'cd {output_dir} && pdflatex -interaction=nonstopmode {tex_filename}',\n",
        "        f'cd {output_dir} && pdflatex -interaction=nonstopmode {tex_filename}'\n",
        "    ]\n",
        "\n",
        "    for i, cmd in enumerate(compile_steps):\n",
        "        logger.log(f\"컴파일 단계 {i+1}/{len(compile_steps)} 실행: {cmd}\")\n",
        "        result = os.system(f'{cmd} > compile_step_{i+1}.log 2>&1')\n",
        "        log_file = os.path.join(output_dir, f'compile_step_{i+1}.log')\n",
        "\n",
        "        if os.path.exists(log_file):\n",
        "            with open(log_file, 'r') as f:\n",
        "                log_content = f.read()\n",
        "                if \"Warning\" in log_content or \"Error\" in log_content:\n",
        "                    logger.log(f\"컴파일 단계 {i+1} 경고/오류:\\n{log_content[:500]}...\", \"WARNING\")\n",
        "                    if i == 1:\n",
        "                        logger.log(f\"BibTeX 로그 전체:\\n{log_content}\", \"WARNING\")\n",
        "\n",
        "        if result != 0:\n",
        "            logger.log(f\"컴파일 단계 {i+1} 오류 (종료 코드: {result})\", \"ERROR\")\n",
        "            if i == 1:\n",
        "                aux_path = os.path.join(output_dir, f'paper{filename_suffix}.aux')\n",
        "                if os.path.exists(aux_path):\n",
        "                    with open(aux_path, 'r') as f:\n",
        "                        aux_content = f.read()\n",
        "                        citation_commands = re.findall(r'\\\\citation{[^}]+}', aux_content)\n",
        "                        logger.log(f\"AUX 파일의 인용 명령어: {citation_commands}\", \"INFO\")\n",
        "                else:\n",
        "                    logger.log(f\"AUX 파일이 존재하지 않음: {aux_path}\", \"ERROR\")\n",
        "\n",
        "    bbl_path = os.path.join(output_dir, f'paper{filename_suffix}.bbl')\n",
        "    if os.path.exists(bbl_path):\n",
        "        with open(bbl_path, 'r') as f:\n",
        "            bbl_content = f.read()\n",
        "            logger.log(f\"BBL 파일 존재 (크기: {len(bbl_content)} bytes)\")\n",
        "            logger.log(f\"BBL 내용 샘플: {bbl_content[:200]}...\")\n",
        "    else:\n",
        "        logger.log(f\"BBL 파일이 존재하지 않음: {bbl_path}\", \"WARNING\")\n",
        "\n",
        "    if os.path.exists(pdf_path):\n",
        "        logger.log(f\"PDF 생성 성공: {pdf_path}\")\n",
        "        return True\n",
        "    else:\n",
        "        logger.log(f\"PDF 생성 실패: {pdf_path}\", \"ERROR\")\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-19"
      },
      "outputs": [],
      "source": [
        "# Cell 19: 품질 검사\n",
        "logger.log(\"논문 품질 검사 시작\")\n",
        "quality_scores = {}\n",
        "\n",
        "for section_name, section_text in sections.items():\n",
        "    score, details = calculate_quality_score(section_text, section_name)\n",
        "    quality_scores[section_name] = (score, details)\n",
        "    logger.log(f\"{section_name} 품질 점수: {score:.2f}\")\n",
        "    logger.log(f\"  세부사항: {details}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-20"
      },
      "outputs": [],
      "source": [
        "# Cell 20: 중간 PDF 생성\n",
        "logger.log(\"섹션별 PDF 생성 시작\")\n",
        "accumulated_sections = {}\n",
        "\n",
        "for section_name in ['abstract', 'introduction', 'related_work', 'methodology', 'experiments', 'conclusion']:\n",
        "    if section_name in sections:\n",
        "        accumulated_sections[section_name] = sections[section_name]\n",
        "        success = generate_latex_and_save_pdf(accumulated_sections, section_name)\n",
        "        if success:\n",
        "            logger.log(f\"{section_name}까지 PDF 생성 완료\")\n",
        "        else:\n",
        "            logger.log(f\"{section_name}까지 PDF 생성 실패\", \"WARNING\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-21"
      },
      "outputs": [],
      "source": [
        "# Cell 21: 최종 PDF 생성\n",
        "logger.log(\"최종 PDF 생성 시작\")\n",
        "final_success = generate_latex_and_save_pdf(sections, paper_title, \"_final\")\n",
        "if final_success:\n",
        "    logger.log(\"최종 PDF 생성 성공\")\n",
        "else:\n",
        "    logger.log(\"최종 PDF 생성 실패\", \"ERROR\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-22"
      },
      "outputs": [],
      "source": [
        "# Cell 22: 결과물 압축 및 저장\n",
        "logger.log(\"최종 결과물 압축 시작\")\n",
        "\n",
        "zip_path = os.path.join(output_dir, 'research_output.zip')\n",
        "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
        "    for filename in os.listdir(output_dir):\n",
        "        if filename.endswith('.pdf'):\n",
        "            file_path = os.path.join(output_dir, filename)\n",
        "            zf.write(file_path, filename)\n",
        "            logger.log(f\"압축 파일에 추가: {filename}\")\n",
        "    for filename in os.listdir(output_dir):\n",
        "        if filename.endswith('.tex'):\n",
        "            file_path = os.path.join(output_dir, filename)\n",
        "            zf.write(file_path, filename)\n",
        "    if os.path.exists(bib_path):\n",
        "        zf.write(bib_path, 'references.bib')\n",
        "    log_file = os.path.join(output_dir, 'research_log.txt')\n",
        "    if os.path.exists(log_file):\n",
        "        zf.write(log_file, 'research_log.txt')\n",
        "    sections_json = os.path.join(output_dir, 'sections.json')\n",
        "    with open(sections_json, 'w', encoding='utf-8') as f:\n",
        "        json.dump(sections, f, ensure_ascii=False, indent=2)\n",
        "    zf.write(sections_json, 'sections.json')\n",
        "\n",
        "logger.log(f\"압축 완료: {zip_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-23"
      },
      "outputs": [],
      "source": [
        "# Cell 23: 결과 요약 및 다운로드\n",
        "all_scores = [score for score, _ in quality_scores.values()]\n",
        "average_quality = sum(all_scores) / len(all_scores) if all_scores else 0.0\n",
        "total_time = time.time() - logger.start_time\n",
        "hours = int(total_time // 3600)\n",
        "minutes = int((total_time % 3600) // 60)\n",
        "seconds = int(total_time % 60)\n",
        "\n",
        "logger.log(\"=\" * 50, \"COMPLETE\")\n",
        "logger.log(f\"연구 논문 작성 완료!\", \"COMPLETE\")\n",
        "logger.log(f\"논문 제목: {paper_title}\", \"COMPLETE\")\n",
        "logger.log(f\"총 소요 시간: {hours:02d}:{minutes:02d}:{seconds:02d}\", \"COMPLETE\")\n",
        "logger.log(f\"평균 품질 점수: {average_quality:.2f}\", \"COMPLETE\")\n",
        "logger.log(f\"결과물 위치: {output_dir}\", \"COMPLETE\")\n",
        "logger.log(\"=\" * 50, \"COMPLETE\")\n",
        "\n",
        "logger.log(\"로컬 다운로드를 원하시면 아래 파일을 다운로드하세요:\")\n",
        "try:\n",
        "    files.download(zip_path)\n",
        "    logger.log(\"다운로드 준비 완료\")\n",
        "except Exception as e:\n",
        "    logger.log(f\"다운로드 오류: {str(e)}\", \"WARNING\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-24"
      },
      "outputs": [],
      "source": [
        "# Cell 24: 디버깅 정보 출력\n",
        "logger.log(\"\\n=== 디버깅 정보 ===\")\n",
        "logger.log(f\"작업 디렉토리 파일 목록:\")\n",
        "for filename in sorted(os.listdir(output_dir)):\n",
        "    file_path = os.path.join(output_dir, filename)\n",
        "    file_size = os.path.getsize(file_path)\n",
        "    logger.log(f\"  - {filename} ({file_size} bytes)\")\n",
        "\n",
        "logger.log(\"\\n생성된 섹션 요약:\")\n",
        "for section_name, content in sections.items():\n",
        "    word_count = len(content.split())\n",
        "    logger.log(f\"  - {section_name}: {word_count} words\")\n",
        "\n",
        "logger.log(\"\\n=== 작업 완료 ===\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}